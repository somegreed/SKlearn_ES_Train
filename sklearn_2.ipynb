{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [安裝anaconda](https://yaojenkuo.io/intro_2_py_ds_esun/chapter0.slides.html#/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [jupyter notebook快捷鍵](http://opus.konghy.cn/ipynb/jupyter-notebook-keyboard-shortcut.html)\n",
    "* ESC鍵、Ctrl+M→進入meta狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [申請Kaggle帳號](https://www.kaggle.com/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![資料類型](https://raw.githubusercontent.com/somegreed/pic/master/1.png)\n",
    "\n",
    "\n",
    "## List沒辦法處理element-wise資料\n",
    "## 透過pandas或numpy.array\n",
    "\n",
    "![array](https://raw.githubusercontent.com/somegreed/pic/master/2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropna()、fillna()\n",
    "![3.png](https://raw.githubusercontent.com/somegreed/pic/master/3.png)\n",
    "![4.png](https://raw.githubusercontent.com/somegreed/pic/master/4.png)\n",
    "![5.png](https://raw.githubusercontent.com/somegreed/pic/master/5.png)\n",
    "![6.png](https://raw.githubusercontent.com/somegreed/pic/master/6.png)\n",
    "\n",
    "## https://pandas.pydata.org/pandas-docs/stable/index.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![7.png](https://raw.githubusercontent.com/somegreed/pic/master/7.png)\n",
    "![8.png](https://raw.githubusercontent.com/somegreed/pic/master/8.png)\n",
    "![9.png](https://raw.githubusercontent.com/somegreed/pic/master/9.png)\n",
    "![10.png](https://raw.githubusercontent.com/somegreed/pic/master/10.png)\n",
    "![11.png](https://raw.githubusercontent.com/somegreed/pic/master/11.png)\n",
    "\n",
    "## 讀資料\n",
    "* [pandas](https://yaojenkuo.io/intro_2_py_ds_esun/chapter4.slides.html#/12)\n",
    "* 讀sas資料 read_sas，但建議轉換成[csv檔](https://stackoverflow.com/questions/48170960/why-is-pandas-read-sas-so-much-slower-than-pandas-read-csv)後再讀入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## [Titanic：Machine Learning from Disater](https://www.kaggle.com/c/titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "#讀資料\n",
    "train_url = \"https://storage.googleapis.com/py_ml_datasets/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "#看資料\n",
    "print train.head(3)\n",
    "print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#事件發生比例與數量\n",
    "print train.Survived.value_counts(normalize=False)\n",
    "print train.Survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#遺漏值件數\n",
    "print train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PassengerId  Survived    Pclass                         Name     Sex  \\\n",
      "max           891.0  1.000000  3.000000  van Melkebeke, Mr. Philemon    male   \n",
      "mean          446.0  0.383838  2.308642                          NaN     NaN   \n",
      "median        446.0  0.000000  3.000000                          NaN     NaN   \n",
      "min             1.0  0.000000  1.000000          Abbing, Mr. Anthony  female   \n",
      "\n",
      "              Age     SibSp     Parch     Ticket        Fare Cabin Embarked  \n",
      "max     80.000000  8.000000  6.000000  WE/P 5735  512.329200     T        S  \n",
      "mean    29.699118  0.523008  0.381594        NaN   32.204208   NaN      NaN  \n",
      "median  28.000000  0.000000  0.000000        NaN   14.454200   NaN      NaN  \n",
      "min      0.420000  0.000000  0.000000     110152    0.000000   inf      inf  \n"
     ]
    }
   ],
   "source": [
    "#變數分布\n",
    "print train.agg(['mean','median','max','min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PassengerId  Survived  Pclass     Age  SibSp  Parch     Fare\n",
      "0.25        223.5       0.0     2.0  20.125    0.0    0.0   7.9104\n",
      "0.75        668.5       1.0     3.0  38.000    1.0    0.0  31.0000\n"
     ]
    }
   ],
   "source": [
    "print train.quantile([0.25,0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PassengerId                             Pclass                       \\\n",
      "               count        mean median  max min  count      mean median max   \n",
      "Survived                                                                       \n",
      "0                549  447.016393  455.0  891   1    549  2.531876      3   3   \n",
      "1                342  444.368421  439.5  890   2    342  1.950292      2   3   \n",
      "\n",
      "             ...  Parch                           Fare                    \\\n",
      "         min ...  count      mean median max min count       mean median   \n",
      "Survived     ...                                                           \n",
      "0          1 ...    549  0.329690      0   6   0   549  22.117887   10.5   \n",
      "1          1 ...    342  0.464912      0   5   0   342  48.395408   26.0   \n",
      "\n",
      "                         \n",
      "               max  min  \n",
      "Survived                 \n",
      "0         263.0000  0.0  \n",
      "1         512.3292  0.0  \n",
      "\n",
      "[2 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print train.groupby('Survived').agg(['count','mean','median','max','min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0    0.811092\n",
      "1    0.188908\n",
      "Name: Survived, dtype: float64\n",
      "\n",
      "\n",
      "0    468\n",
      "1    109\n",
      "Name: Survived, dtype: int64\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "\n",
      "C    168\n",
      "Q     77\n",
      "S    644\n",
      "Name: Embarked, dtype: int64\n",
      "NaN      2\n",
      "C      168\n",
      "Q       77\n",
      "S      644\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#補值\n",
    "print train.Survived.isnull().sum()\n",
    "print train.Survived[train.Sex == 'male'].value_counts(normalize = True, sort = False)\n",
    "print \"\\n\"\n",
    "print train.Survived[train.Sex == 'male'].value_counts(normalize = False, sort = False)\n",
    "print train.Survived.value_counts(normalize = False, sort = False)\n",
    "print \"\\n\"\n",
    "print train.Embarked.value_counts(normalize = False, sort = False)\n",
    "print train.Embarked.value_counts(normalize = False, sort = False,dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "most_embarked = train.Embarked.value_counts().index[0]\n",
    "print most_embarked\n",
    "train.Embarked = train.Embarked.fillna(most_embarked)\n",
    "print sum(train.Embarked.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "age_median = train.Age.median()\n",
    "print sum(train.Age.isnull())\n",
    "train.Age = train.Age.fillna(age_median)\n",
    "print sum(train.Age.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S\n",
      "0           0         1           0           0           1\n",
      "1           1         0           1           0           0\n",
      "2           1         0           0           0           1\n"
     ]
    }
   ],
   "source": [
    "#變數轉換 one-hot encodeing\n",
    "train_sex_embarked_dummies = pd.get_dummies(train.loc[:, [\"Sex\", \"Embarked\"]])\n",
    "print train_sex_embarked_dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  \\\n",
      "0            1         0       3  22.0      1      0   7.2500   \n",
      "1            2         1       1  38.0      1      0  71.2833   \n",
      "2            3         1       3  26.0      0      0   7.9250   \n",
      "\n",
      "   Name_Abbing, Mr. Anthony  Name_Abbott, Mr. Rossmore Edward  \\\n",
      "0                         0                                 0   \n",
      "1                         0                                 0   \n",
      "2                         0                                 0   \n",
      "\n",
      "   Name_Abbott, Mrs. Stanton (Rosa Hunt)     ...      Cabin_F G73  Cabin_F2  \\\n",
      "0                                      0     ...                0         0   \n",
      "1                                      0     ...                0         0   \n",
      "2                                      0     ...                0         0   \n",
      "\n",
      "   Cabin_F33  Cabin_F38  Cabin_F4  Cabin_G6  Cabin_T  Embarked_C  Embarked_Q  \\\n",
      "0          0          0         0         0        0           0           0   \n",
      "1          0          0         0         0        0           1           0   \n",
      "2          0          0         0         0        0           0           0   \n",
      "\n",
      "   Embarked_S  \n",
      "0           1  \n",
      "1           0  \n",
      "2           1  \n",
      "\n",
      "[3 rows x 1731 columns]\n"
     ]
    }
   ],
   "source": [
    "train_dummies=pd.get_dummies(train)\n",
    "print train_dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0            1         0       3    male  22.0      1      0   7.2500        S\n",
      "1            2         1       1  female  38.0      1      0  71.2833        C\n",
      "2            3         1       3  female  26.0      0      0   7.9250        S\n"
     ]
    }
   ],
   "source": [
    "train_drop=train.copy()\n",
    "train_drop.drop([\"Cabin\",\"Name\",\"Ticket\"],inplace=True,axis=1)\n",
    "print train_drop.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
      "0            1         0       3  22.0      1      0   7.2500           0   \n",
      "1            2         1       1  38.0      1      0  71.2833           1   \n",
      "2            3         1       3  26.0      0      0   7.9250           1   \n",
      "\n",
      "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0         1           0           0           1  \n",
      "1         0           1           0           0  \n",
      "2         0           0           0           1  \n"
     ]
    }
   ],
   "source": [
    "train_drop_dummies=pd.get_dummies(train_drop)\n",
    "print train_drop_dummies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
      "0            1       3  22.0      1      0   7.2500           0         1   \n",
      "1            2       1  38.0      1      0  71.2833           1         0   \n",
      "2            3       3  26.0      0      0   7.9250           1         0   \n",
      "\n",
      "   Embarked_C  Embarked_Q  Embarked_S  \n",
      "0           0           0           1  \n",
      "1           1           0           0  \n",
      "2           0           0           1  \n"
     ]
    }
   ],
   "source": [
    "# 整理 features 跟 target\n",
    "train_features = train_drop_dummies.copy()\n",
    "train_features.drop(['Survived'],axis=1,inplace=True)\n",
    "print train_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "target=train_drop_dummies.Survived.values\n",
    "print target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Partition](https://yaojenkuo.io/intro_2_py_ds_esun/chapter7.slides.html#/6/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, target, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [決策樹](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=87, splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "# 建立模型\n",
    "# random_state確保每次跑的結果是一樣的\n",
    "tree_clf = tree.DecisionTreeClassifier(criterion = 'entropy', random_state = 87)\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [評估指標](https://yaojenkuo.io/intro_2_py_ds_esun/chapter7.slides.html#/7)\n",
    "* [F1 Score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
    "* [Recall](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
    "* [ROC](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)\n",
    "* [Cross-Validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.694835680751\n",
      "1.0\n",
      "0.718446601942\n",
      "1.0\n",
      "0.75013239188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "predictions_tree_train = tree_clf.predict(X_train)\n",
    "predictions_tree_test = tree_clf.predict(X_test)\n",
    "f1_train = f1_score(y_train, predictions_tree_train)\n",
    "f1_test = f1_score(y_test, predictions_tree_test)\n",
    "recall_train = recall_score(y_train, predictions_tree_train)\n",
    "recall_test = recall_score(y_test, predictions_tree_test)\n",
    "roc_train = roc_auc_score(y_train, predictions_tree_train)\n",
    "roc_test = roc_auc_score(y_test, predictions_tree_test)\n",
    "\n",
    "print f1_train\n",
    "print f1_test\n",
    "print recall_train\n",
    "print recall_test\n",
    "print roc_train\n",
    "print roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621594703331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores_f1 = cross_val_score(tree_clf, train_features, target, cv=5,scoring=\"f1\")\n",
    "print scores_f1.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603282182438\n"
     ]
    }
   ],
   "source": [
    "scores_recall = cross_val_score(tree_clf, train_features, target, cv=5,scoring=\"recall\")\n",
    "print scores_recall.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [羅輯斯迴歸](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=99, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_clf = LogisticRegression(random_state=99)\n",
    "LR_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.733333333333\n",
      "0.71921182266\n",
      "0.690376569038\n",
      "0.708737864078\n",
      "0.785292451185\n",
      "0.772550750221\n"
     ]
    }
   ],
   "source": [
    "predictions_lr_train = LR_clf.predict(X_train)\n",
    "predictions_lr_test = LR_clf.predict(X_test)\n",
    "f1_train = f1_score(y_train, predictions_lr_train)\n",
    "f1_test = f1_score(y_test, predictions_lr_test)\n",
    "recall_train = recall_score(y_train, predictions_lr_train)\n",
    "recall_test = recall_score(y_test, predictions_lr_test)\n",
    "roc_train = roc_auc_score(y_train, predictions_lr_train)\n",
    "roc_test = roc_auc_score(y_test, predictions_lr_test)\n",
    "\n",
    "print f1_train\n",
    "print f1_test\n",
    "print recall_train\n",
    "print recall_test\n",
    "print roc_train\n",
    "print roc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SVM](http://scikit-learn.org/stable/modules/svm.html)\n",
    "* [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Wall time: 19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=87, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# 建立模型\n",
    "%time svm_clf = SVC(kernel = 'linear', random_state = 87)\n",
    "%time svm_clf.fit(X_train, y_train)\n",
    "#%timeit svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726862302483\n",
      "0.710659898477\n",
      "0.673640167364\n",
      "0.679611650485\n",
      "0.780830500349\n",
      "0.767078552515\n"
     ]
    }
   ],
   "source": [
    "predictions_svc_train = svm_clf.predict(X_train)\n",
    "predictions_svc_test = svm_clf.predict(X_test)\n",
    "f1_train = f1_score(y_train, predictions_svc_train)\n",
    "f1_test = f1_score(y_test, predictions_svc_test)\n",
    "recall_train = recall_score(y_train, predictions_svc_train)\n",
    "recall_test = recall_score(y_test, predictions_svc_test)\n",
    "roc_train = roc_auc_score(y_train, predictions_svc_train)\n",
    "roc_test = roc_auc_score(y_test, predictions_svc_test)\n",
    "\n",
    "print f1_train\n",
    "print f1_test\n",
    "print recall_train\n",
    "print recall_test\n",
    "print roc_train\n",
    "print roc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [隨機森林](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=87,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 建立模型\n",
    "forest_clf = RandomForestClassifier(max_depth = 10, min_samples_split = 5, n_estimators = 100,\\\n",
    "                                    random_state = 87, criterion = 'entropy')\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911111111111\n",
      "0.748768472906\n",
      "0.857740585774\n",
      "0.73786407767\n",
      "0.921057792887\n",
      "0.796204766108\n"
     ]
    }
   ],
   "source": [
    "predictions_rf_train = forest_clf.predict(X_train)\n",
    "predictions_rf_test = forest_clf.predict(X_test)\n",
    "f1_train = f1_score(y_train, predictions_rf_train)\n",
    "f1_test = f1_score(y_test, predictions_rf_test)\n",
    "recall_train = recall_score(y_train, predictions_rf_train)\n",
    "recall_test = recall_score(y_test, predictions_rf_test)\n",
    "roc_train = roc_auc_score(y_train, predictions_rf_train)\n",
    "roc_test = roc_auc_score(y_test, predictions_rf_test)\n",
    "\n",
    "print f1_train\n",
    "print f1_test\n",
    "print recall_train\n",
    "print recall_test\n",
    "print roc_train\n",
    "print roc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "* [多數決](https://yaojenkuo.io/intro_2_py_ds_esun/chapter7.slides.html#/10/2)\n",
    "* [VotingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813559322034\n",
      "0.715789473684\n",
      "0.702928870293\n",
      "0.660194174757\n",
      "0.843651935146\n",
      "0.772521329803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf = VotingClassifier(estimators=[('tree', tree_clf), ('LR', LR_clf), ('svc', svm_clf),\\\n",
    "                                    ('forest',forest_clf)])\n",
    "eclf.fit(X_train, y_train)\n",
    "predictions_eclf_train = eclf.predict(X_train)\n",
    "predictions_eclf_test = eclf.predict(X_test)\n",
    "f1_train = f1_score(y_train, predictions_eclf_train)\n",
    "f1_test = f1_score(y_test, predictions_eclf_test)\n",
    "recall_train = recall_score(y_train, predictions_eclf_train)\n",
    "recall_test = recall_score(y_test, predictions_eclf_test)\n",
    "roc_train = roc_auc_score(y_train, predictions_eclf_train)\n",
    "roc_test = roc_auc_score(y_test, predictions_eclf_test)\n",
    "print f1_train\n",
    "print f1_test\n",
    "print recall_train\n",
    "print recall_test\n",
    "print roc_train\n",
    "print roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    male  34.5      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "2          894       2         Myles, Mr. Thomas Francis    male  62.0      0   \n",
       "\n",
       "   Parch  Ticket    Fare Cabin Embarked  \n",
       "0      0  330911  7.8292   NaN        Q  \n",
       "1      0  363272  7.0000   NaN        S  \n",
       "2      0  240276  9.6875   NaN        Q  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_url = \"https://storage.googleapis.com/py_ml_datasets/test.csv\"\n",
    "test = pd.read_csv(test_url)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print test.shape\n",
    "print test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Age 的遺漏值以中位數填補\n",
    "age_median = test.Age.median()\n",
    "test.Age = test.Age.fillna(age_median)\n",
    "print sum(test.Age.isnull())\n",
    "\n",
    "# Fare 的遺漏值以平均數填補\n",
    "fare_median = test.Fare.median()\n",
    "test.Fare = test.Fare.fillna(fare_median)\n",
    "print sum(test.Fare.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "test_drop=test.copy()\n",
    "test_drop.drop([\"Cabin\",\"Name\",\"Ticket\"],inplace=True,axis=1)\n",
    "test_drop_dummies=pd.get_dummies(test_drop)\n",
    "test_features = test_drop_dummies.copy()\n",
    "\n",
    "# 預估\n",
    "predictions = forest_clf.predict(test_features)\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived\n",
      "892         0\n",
      "893         0\n",
      "894         0\n",
      "895         0\n",
      "896         0\n",
      "(418, 1)\n"
     ]
    }
   ],
   "source": [
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(predictions, PassengerId,columns = [\"Survived\"])\n",
    "print my_solution.head()\n",
    "print my_solution.shape\n",
    "my_solution.to_csv(\"test.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'C:\\\\Users\\\\typhone'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "# shift tab說明\n",
    "# tab補完指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%time df=pdr.get_data_yahoo('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>30.447144</td>\n",
       "      <td>30.478571</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>30.104286</td>\n",
       "      <td>20.301006</td>\n",
       "      <td>88102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>30.490000</td>\n",
       "      <td>30.642857</td>\n",
       "      <td>30.340000</td>\n",
       "      <td>30.572857</td>\n",
       "      <td>20.616993</td>\n",
       "      <td>123432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>30.657143</td>\n",
       "      <td>30.798571</td>\n",
       "      <td>30.464285</td>\n",
       "      <td>30.625713</td>\n",
       "      <td>20.652637</td>\n",
       "      <td>150476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>30.625713</td>\n",
       "      <td>30.747143</td>\n",
       "      <td>30.107143</td>\n",
       "      <td>30.138571</td>\n",
       "      <td>20.324135</td>\n",
       "      <td>138040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>30.285715</td>\n",
       "      <td>29.864286</td>\n",
       "      <td>30.082857</td>\n",
       "      <td>20.286560</td>\n",
       "      <td>119282800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "2009-12-31  30.447144  30.478571  30.080000  30.104286  20.301006   88102700\n",
       "2010-01-04  30.490000  30.642857  30.340000  30.572857  20.616993  123432400\n",
       "2010-01-05  30.657143  30.798571  30.464285  30.625713  20.652637  150476200\n",
       "2010-01-06  30.625713  30.747143  30.107143  30.138571  20.324135  138040000\n",
       "2010-01-07  30.250000  30.285715  29.864286  30.082857  20.286560  119282800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-27</th>\n",
       "      <td>143.919998</td>\n",
       "      <td>144.160004</td>\n",
       "      <td>143.309998</td>\n",
       "      <td>143.789993</td>\n",
       "      <td>141.007004</td>\n",
       "      <td>14246300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-28</th>\n",
       "      <td>144.089996</td>\n",
       "      <td>144.300003</td>\n",
       "      <td>143.270004</td>\n",
       "      <td>143.649994</td>\n",
       "      <td>140.869705</td>\n",
       "      <td>20860400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>145.100006</td>\n",
       "      <td>147.199997</td>\n",
       "      <td>144.960007</td>\n",
       "      <td>146.580002</td>\n",
       "      <td>143.743011</td>\n",
       "      <td>33602900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-02</th>\n",
       "      <td>147.539993</td>\n",
       "      <td>148.089996</td>\n",
       "      <td>146.839996</td>\n",
       "      <td>147.509995</td>\n",
       "      <td>144.654999</td>\n",
       "      <td>45352200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-03</th>\n",
       "      <td>145.589996</td>\n",
       "      <td>147.490005</td>\n",
       "      <td>144.270004</td>\n",
       "      <td>147.059998</td>\n",
       "      <td>144.213715</td>\n",
       "      <td>45697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-04</th>\n",
       "      <td>146.520004</td>\n",
       "      <td>147.139999</td>\n",
       "      <td>145.809998</td>\n",
       "      <td>146.529999</td>\n",
       "      <td>143.693954</td>\n",
       "      <td>23371900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-05</th>\n",
       "      <td>146.759995</td>\n",
       "      <td>148.979996</td>\n",
       "      <td>146.759995</td>\n",
       "      <td>148.960007</td>\n",
       "      <td>146.076935</td>\n",
       "      <td>27327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-08</th>\n",
       "      <td>149.029999</td>\n",
       "      <td>153.699997</td>\n",
       "      <td>149.029999</td>\n",
       "      <td>153.009995</td>\n",
       "      <td>150.048538</td>\n",
       "      <td>48752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-09</th>\n",
       "      <td>153.869995</td>\n",
       "      <td>154.880005</td>\n",
       "      <td>153.449997</td>\n",
       "      <td>153.990005</td>\n",
       "      <td>151.009598</td>\n",
       "      <td>39130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-10</th>\n",
       "      <td>153.630005</td>\n",
       "      <td>153.940002</td>\n",
       "      <td>152.110001</td>\n",
       "      <td>153.259995</td>\n",
       "      <td>150.293716</td>\n",
       "      <td>25805700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-11</th>\n",
       "      <td>152.449997</td>\n",
       "      <td>154.070007</td>\n",
       "      <td>152.309998</td>\n",
       "      <td>153.949997</td>\n",
       "      <td>151.593491</td>\n",
       "      <td>27255100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-12</th>\n",
       "      <td>154.699997</td>\n",
       "      <td>156.419998</td>\n",
       "      <td>154.669998</td>\n",
       "      <td>156.100006</td>\n",
       "      <td>153.710602</td>\n",
       "      <td>32527000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-15</th>\n",
       "      <td>156.009995</td>\n",
       "      <td>156.649994</td>\n",
       "      <td>155.050003</td>\n",
       "      <td>155.699997</td>\n",
       "      <td>153.316727</td>\n",
       "      <td>26009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-16</th>\n",
       "      <td>155.940002</td>\n",
       "      <td>156.059998</td>\n",
       "      <td>154.720001</td>\n",
       "      <td>155.470001</td>\n",
       "      <td>153.090256</td>\n",
       "      <td>20048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17</th>\n",
       "      <td>153.600006</td>\n",
       "      <td>154.570007</td>\n",
       "      <td>149.710007</td>\n",
       "      <td>150.250000</td>\n",
       "      <td>147.950150</td>\n",
       "      <td>50767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-18</th>\n",
       "      <td>151.270004</td>\n",
       "      <td>153.339996</td>\n",
       "      <td>151.130005</td>\n",
       "      <td>152.539993</td>\n",
       "      <td>150.205078</td>\n",
       "      <td>33568200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-19</th>\n",
       "      <td>153.380005</td>\n",
       "      <td>153.979996</td>\n",
       "      <td>152.630005</td>\n",
       "      <td>153.059998</td>\n",
       "      <td>150.717133</td>\n",
       "      <td>26960800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.580002</td>\n",
       "      <td>152.910004</td>\n",
       "      <td>153.990005</td>\n",
       "      <td>151.632904</td>\n",
       "      <td>22966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-23</th>\n",
       "      <td>154.899994</td>\n",
       "      <td>154.899994</td>\n",
       "      <td>153.309998</td>\n",
       "      <td>153.800003</td>\n",
       "      <td>151.445801</td>\n",
       "      <td>19918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-24</th>\n",
       "      <td>153.839996</td>\n",
       "      <td>154.169998</td>\n",
       "      <td>152.669998</td>\n",
       "      <td>153.339996</td>\n",
       "      <td>150.992844</td>\n",
       "      <td>19178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-25</th>\n",
       "      <td>153.729996</td>\n",
       "      <td>154.350006</td>\n",
       "      <td>153.029999</td>\n",
       "      <td>153.869995</td>\n",
       "      <td>151.514725</td>\n",
       "      <td>19235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-26</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.240005</td>\n",
       "      <td>153.309998</td>\n",
       "      <td>153.610001</td>\n",
       "      <td>151.258728</td>\n",
       "      <td>21701100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-30</th>\n",
       "      <td>153.419998</td>\n",
       "      <td>154.429993</td>\n",
       "      <td>153.330002</td>\n",
       "      <td>153.669998</td>\n",
       "      <td>151.317795</td>\n",
       "      <td>20126900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>153.970001</td>\n",
       "      <td>154.169998</td>\n",
       "      <td>152.380005</td>\n",
       "      <td>152.759995</td>\n",
       "      <td>150.421722</td>\n",
       "      <td>24451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-01</th>\n",
       "      <td>153.169998</td>\n",
       "      <td>153.330002</td>\n",
       "      <td>152.220001</td>\n",
       "      <td>153.179993</td>\n",
       "      <td>150.835281</td>\n",
       "      <td>16404100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-02</th>\n",
       "      <td>153.580002</td>\n",
       "      <td>155.449997</td>\n",
       "      <td>152.889999</td>\n",
       "      <td>155.449997</td>\n",
       "      <td>153.070541</td>\n",
       "      <td>27770700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-05</th>\n",
       "      <td>154.339996</td>\n",
       "      <td>154.449997</td>\n",
       "      <td>153.460007</td>\n",
       "      <td>153.929993</td>\n",
       "      <td>151.573807</td>\n",
       "      <td>25331700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06</th>\n",
       "      <td>153.899994</td>\n",
       "      <td>155.809998</td>\n",
       "      <td>153.779999</td>\n",
       "      <td>154.449997</td>\n",
       "      <td>152.085846</td>\n",
       "      <td>26624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-07</th>\n",
       "      <td>155.020004</td>\n",
       "      <td>155.979996</td>\n",
       "      <td>154.479996</td>\n",
       "      <td>155.369995</td>\n",
       "      <td>152.991776</td>\n",
       "      <td>21069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-08</th>\n",
       "      <td>155.250000</td>\n",
       "      <td>155.539993</td>\n",
       "      <td>154.399994</td>\n",
       "      <td>154.990005</td>\n",
       "      <td>152.617584</td>\n",
       "      <td>21250800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-23</th>\n",
       "      <td>186.350006</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>185.759995</td>\n",
       "      <td>188.360001</td>\n",
       "      <td>188.360001</td>\n",
       "      <td>19467900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-24</th>\n",
       "      <td>188.770004</td>\n",
       "      <td>188.839996</td>\n",
       "      <td>186.210007</td>\n",
       "      <td>188.149994</td>\n",
       "      <td>188.149994</td>\n",
       "      <td>20401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-25</th>\n",
       "      <td>188.229996</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>187.649994</td>\n",
       "      <td>188.580002</td>\n",
       "      <td>188.580002</td>\n",
       "      <td>17461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>187.600006</td>\n",
       "      <td>188.750000</td>\n",
       "      <td>186.869995</td>\n",
       "      <td>187.899994</td>\n",
       "      <td>187.899994</td>\n",
       "      <td>22369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>187.720001</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>186.779999</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>187.500000</td>\n",
       "      <td>18690500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>187.220001</td>\n",
       "      <td>188.229996</td>\n",
       "      <td>186.139999</td>\n",
       "      <td>186.869995</td>\n",
       "      <td>186.869995</td>\n",
       "      <td>27482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>187.990005</td>\n",
       "      <td>190.259995</td>\n",
       "      <td>187.750000</td>\n",
       "      <td>190.240005</td>\n",
       "      <td>190.240005</td>\n",
       "      <td>23250400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-04</th>\n",
       "      <td>191.639999</td>\n",
       "      <td>193.419998</td>\n",
       "      <td>191.350006</td>\n",
       "      <td>191.830002</td>\n",
       "      <td>191.830002</td>\n",
       "      <td>26132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-05</th>\n",
       "      <td>193.070007</td>\n",
       "      <td>193.940002</td>\n",
       "      <td>192.360001</td>\n",
       "      <td>193.309998</td>\n",
       "      <td>193.309998</td>\n",
       "      <td>21566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-06</th>\n",
       "      <td>193.630005</td>\n",
       "      <td>194.080002</td>\n",
       "      <td>191.919998</td>\n",
       "      <td>193.979996</td>\n",
       "      <td>193.979996</td>\n",
       "      <td>20933600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07</th>\n",
       "      <td>194.139999</td>\n",
       "      <td>194.199997</td>\n",
       "      <td>192.339996</td>\n",
       "      <td>193.460007</td>\n",
       "      <td>193.460007</td>\n",
       "      <td>21347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-08</th>\n",
       "      <td>191.169998</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>189.770004</td>\n",
       "      <td>191.699997</td>\n",
       "      <td>191.699997</td>\n",
       "      <td>26656800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-11</th>\n",
       "      <td>191.350006</td>\n",
       "      <td>191.970001</td>\n",
       "      <td>190.210007</td>\n",
       "      <td>191.229996</td>\n",
       "      <td>191.229996</td>\n",
       "      <td>18308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-12</th>\n",
       "      <td>191.389999</td>\n",
       "      <td>192.610001</td>\n",
       "      <td>191.149994</td>\n",
       "      <td>192.279999</td>\n",
       "      <td>192.279999</td>\n",
       "      <td>16911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-13</th>\n",
       "      <td>192.419998</td>\n",
       "      <td>192.880005</td>\n",
       "      <td>190.440002</td>\n",
       "      <td>190.699997</td>\n",
       "      <td>190.699997</td>\n",
       "      <td>21638400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-14</th>\n",
       "      <td>191.550003</td>\n",
       "      <td>191.570007</td>\n",
       "      <td>190.220001</td>\n",
       "      <td>190.800003</td>\n",
       "      <td>190.800003</td>\n",
       "      <td>21610100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-15</th>\n",
       "      <td>190.029999</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>188.259995</td>\n",
       "      <td>188.839996</td>\n",
       "      <td>188.839996</td>\n",
       "      <td>61719200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-18</th>\n",
       "      <td>187.880005</td>\n",
       "      <td>189.220001</td>\n",
       "      <td>187.199997</td>\n",
       "      <td>188.740005</td>\n",
       "      <td>188.740005</td>\n",
       "      <td>18484900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-19</th>\n",
       "      <td>185.139999</td>\n",
       "      <td>186.330002</td>\n",
       "      <td>183.449997</td>\n",
       "      <td>185.690002</td>\n",
       "      <td>185.690002</td>\n",
       "      <td>33578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-20</th>\n",
       "      <td>186.350006</td>\n",
       "      <td>187.199997</td>\n",
       "      <td>185.729996</td>\n",
       "      <td>186.500000</td>\n",
       "      <td>186.500000</td>\n",
       "      <td>20628700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-21</th>\n",
       "      <td>187.250000</td>\n",
       "      <td>188.350006</td>\n",
       "      <td>184.940002</td>\n",
       "      <td>185.460007</td>\n",
       "      <td>185.460007</td>\n",
       "      <td>25711900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-22</th>\n",
       "      <td>186.119995</td>\n",
       "      <td>186.149994</td>\n",
       "      <td>184.699997</td>\n",
       "      <td>184.919998</td>\n",
       "      <td>184.919998</td>\n",
       "      <td>27200400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25</th>\n",
       "      <td>183.399994</td>\n",
       "      <td>184.919998</td>\n",
       "      <td>180.729996</td>\n",
       "      <td>182.169998</td>\n",
       "      <td>182.169998</td>\n",
       "      <td>31663100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-26</th>\n",
       "      <td>182.990005</td>\n",
       "      <td>186.529999</td>\n",
       "      <td>182.539993</td>\n",
       "      <td>184.429993</td>\n",
       "      <td>184.429993</td>\n",
       "      <td>24569200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-27</th>\n",
       "      <td>185.229996</td>\n",
       "      <td>187.279999</td>\n",
       "      <td>184.029999</td>\n",
       "      <td>184.160004</td>\n",
       "      <td>184.160004</td>\n",
       "      <td>25285300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>184.100006</td>\n",
       "      <td>186.210007</td>\n",
       "      <td>183.800003</td>\n",
       "      <td>185.500000</td>\n",
       "      <td>185.500000</td>\n",
       "      <td>17365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>186.289993</td>\n",
       "      <td>187.190002</td>\n",
       "      <td>182.910004</td>\n",
       "      <td>185.110001</td>\n",
       "      <td>185.110001</td>\n",
       "      <td>22737700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-02</th>\n",
       "      <td>183.820007</td>\n",
       "      <td>187.300003</td>\n",
       "      <td>183.419998</td>\n",
       "      <td>187.179993</td>\n",
       "      <td>187.179993</td>\n",
       "      <td>17731300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03</th>\n",
       "      <td>187.789993</td>\n",
       "      <td>187.949997</td>\n",
       "      <td>183.539993</td>\n",
       "      <td>183.919998</td>\n",
       "      <td>183.919998</td>\n",
       "      <td>13954800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05</th>\n",
       "      <td>185.259995</td>\n",
       "      <td>186.410004</td>\n",
       "      <td>184.279999</td>\n",
       "      <td>185.399994</td>\n",
       "      <td>185.399994</td>\n",
       "      <td>16581500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2017-04-27  143.919998  144.160004  143.309998  143.789993  141.007004   \n",
       "2017-04-28  144.089996  144.300003  143.270004  143.649994  140.869705   \n",
       "2017-05-01  145.100006  147.199997  144.960007  146.580002  143.743011   \n",
       "2017-05-02  147.539993  148.089996  146.839996  147.509995  144.654999   \n",
       "2017-05-03  145.589996  147.490005  144.270004  147.059998  144.213715   \n",
       "2017-05-04  146.520004  147.139999  145.809998  146.529999  143.693954   \n",
       "2017-05-05  146.759995  148.979996  146.759995  148.960007  146.076935   \n",
       "2017-05-08  149.029999  153.699997  149.029999  153.009995  150.048538   \n",
       "2017-05-09  153.869995  154.880005  153.449997  153.990005  151.009598   \n",
       "2017-05-10  153.630005  153.940002  152.110001  153.259995  150.293716   \n",
       "2017-05-11  152.449997  154.070007  152.309998  153.949997  151.593491   \n",
       "2017-05-12  154.699997  156.419998  154.669998  156.100006  153.710602   \n",
       "2017-05-15  156.009995  156.649994  155.050003  155.699997  153.316727   \n",
       "2017-05-16  155.940002  156.059998  154.720001  155.470001  153.090256   \n",
       "2017-05-17  153.600006  154.570007  149.710007  150.250000  147.950150   \n",
       "2017-05-18  151.270004  153.339996  151.130005  152.539993  150.205078   \n",
       "2017-05-19  153.380005  153.979996  152.630005  153.059998  150.717133   \n",
       "2017-05-22  154.000000  154.580002  152.910004  153.990005  151.632904   \n",
       "2017-05-23  154.899994  154.899994  153.309998  153.800003  151.445801   \n",
       "2017-05-24  153.839996  154.169998  152.669998  153.339996  150.992844   \n",
       "2017-05-25  153.729996  154.350006  153.029999  153.869995  151.514725   \n",
       "2017-05-26  154.000000  154.240005  153.309998  153.610001  151.258728   \n",
       "2017-05-30  153.419998  154.429993  153.330002  153.669998  151.317795   \n",
       "2017-05-31  153.970001  154.169998  152.380005  152.759995  150.421722   \n",
       "2017-06-01  153.169998  153.330002  152.220001  153.179993  150.835281   \n",
       "2017-06-02  153.580002  155.449997  152.889999  155.449997  153.070541   \n",
       "2017-06-05  154.339996  154.449997  153.460007  153.929993  151.573807   \n",
       "2017-06-06  153.899994  155.809998  153.779999  154.449997  152.085846   \n",
       "2017-06-07  155.020004  155.979996  154.479996  155.369995  152.991776   \n",
       "2017-06-08  155.250000  155.539993  154.399994  154.990005  152.617584   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2018-05-23  186.350006  188.500000  185.759995  188.360001  188.360001   \n",
       "2018-05-24  188.770004  188.839996  186.210007  188.149994  188.149994   \n",
       "2018-05-25  188.229996  189.649994  187.649994  188.580002  188.580002   \n",
       "2018-05-29  187.600006  188.750000  186.869995  187.899994  187.899994   \n",
       "2018-05-30  187.720001  188.000000  186.779999  187.500000  187.500000   \n",
       "2018-05-31  187.220001  188.229996  186.139999  186.869995  186.869995   \n",
       "2018-06-01  187.990005  190.259995  187.750000  190.240005  190.240005   \n",
       "2018-06-04  191.639999  193.419998  191.350006  191.830002  191.830002   \n",
       "2018-06-05  193.070007  193.940002  192.360001  193.309998  193.309998   \n",
       "2018-06-06  193.630005  194.080002  191.919998  193.979996  193.979996   \n",
       "2018-06-07  194.139999  194.199997  192.339996  193.460007  193.460007   \n",
       "2018-06-08  191.169998  192.000000  189.770004  191.699997  191.699997   \n",
       "2018-06-11  191.350006  191.970001  190.210007  191.229996  191.229996   \n",
       "2018-06-12  191.389999  192.610001  191.149994  192.279999  192.279999   \n",
       "2018-06-13  192.419998  192.880005  190.440002  190.699997  190.699997   \n",
       "2018-06-14  191.550003  191.570007  190.220001  190.800003  190.800003   \n",
       "2018-06-15  190.029999  190.160004  188.259995  188.839996  188.839996   \n",
       "2018-06-18  187.880005  189.220001  187.199997  188.740005  188.740005   \n",
       "2018-06-19  185.139999  186.330002  183.449997  185.690002  185.690002   \n",
       "2018-06-20  186.350006  187.199997  185.729996  186.500000  186.500000   \n",
       "2018-06-21  187.250000  188.350006  184.940002  185.460007  185.460007   \n",
       "2018-06-22  186.119995  186.149994  184.699997  184.919998  184.919998   \n",
       "2018-06-25  183.399994  184.919998  180.729996  182.169998  182.169998   \n",
       "2018-06-26  182.990005  186.529999  182.539993  184.429993  184.429993   \n",
       "2018-06-27  185.229996  187.279999  184.029999  184.160004  184.160004   \n",
       "2018-06-28  184.100006  186.210007  183.800003  185.500000  185.500000   \n",
       "2018-06-29  186.289993  187.190002  182.910004  185.110001  185.110001   \n",
       "2018-07-02  183.820007  187.300003  183.419998  187.179993  187.179993   \n",
       "2018-07-03  187.789993  187.949997  183.539993  183.919998  183.919998   \n",
       "2018-07-05  185.259995  186.410004  184.279999  185.399994  185.399994   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2017-04-27  14246300  \n",
       "2017-04-28  20860400  \n",
       "2017-05-01  33602900  \n",
       "2017-05-02  45352200  \n",
       "2017-05-03  45697000  \n",
       "2017-05-04  23371900  \n",
       "2017-05-05  27327700  \n",
       "2017-05-08  48752400  \n",
       "2017-05-09  39130400  \n",
       "2017-05-10  25805700  \n",
       "2017-05-11  27255100  \n",
       "2017-05-12  32527000  \n",
       "2017-05-15  26009700  \n",
       "2017-05-16  20048500  \n",
       "2017-05-17  50767700  \n",
       "2017-05-18  33568200  \n",
       "2017-05-19  26960800  \n",
       "2017-05-22  22966400  \n",
       "2017-05-23  19918900  \n",
       "2017-05-24  19178000  \n",
       "2017-05-25  19235600  \n",
       "2017-05-26  21701100  \n",
       "2017-05-30  20126900  \n",
       "2017-05-31  24451200  \n",
       "2017-06-01  16404100  \n",
       "2017-06-02  27770700  \n",
       "2017-06-05  25331700  \n",
       "2017-06-06  26624900  \n",
       "2017-06-07  21069600  \n",
       "2017-06-08  21250800  \n",
       "...              ...  \n",
       "2018-05-23  19467900  \n",
       "2018-05-24  20401000  \n",
       "2018-05-25  17461000  \n",
       "2018-05-29  22369000  \n",
       "2018-05-30  18690500  \n",
       "2018-05-31  27482800  \n",
       "2018-06-01  23250400  \n",
       "2018-06-04  26132000  \n",
       "2018-06-05  21566000  \n",
       "2018-06-06  20933600  \n",
       "2018-06-07  21347200  \n",
       "2018-06-08  26656800  \n",
       "2018-06-11  18308500  \n",
       "2018-06-12  16911100  \n",
       "2018-06-13  21638400  \n",
       "2018-06-14  21610100  \n",
       "2018-06-15  61719200  \n",
       "2018-06-18  18484900  \n",
       "2018-06-19  33578500  \n",
       "2018-06-20  20628700  \n",
       "2018-06-21  25711900  \n",
       "2018-06-22  27200400  \n",
       "2018-06-25  31663100  \n",
       "2018-06-26  24569200  \n",
       "2018-06-27  25285300  \n",
       "2018-06-28  17365200  \n",
       "2018-06-29  22737700  \n",
       "2018-07-02  17731300  \n",
       "2018-07-03  13954800  \n",
       "2018-07-05  16581500  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-300:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quandl https://www.quandl.com/tools/python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
